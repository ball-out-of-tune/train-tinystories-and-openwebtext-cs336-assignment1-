def compute_percentage_eachpart(context_length: int, d_model: int, vocab_size: int, num_layers: int):
    """
    1
    Xåˆ†åˆ«ä¹˜ä»¥Q K V
    """
    flops_qkv = 6 * context_length * d_model * d_model

    """
    2
    æŒ‰ head è®¡ç®—çš„ç‚¹ç§¯æ³¨æ„åŠ›å¾—åˆ†ï¼š
      æ¯ head FLOPs = 2 â‹… ğ¿ â‹… ğ¿ â‹… ğ‘‘_ğ‘˜ =2â‹…Lâ‹…Lâ‹…d_k â€‹ ã€‚å› ä¸º âˆ‘ â„ ğ‘‘ ğ‘˜ = ğ‘‘ âˆ‘ h â€‹ d k â€‹ =dï¼Œæ‰€ä»¥åˆå¹¶ä¸º:FLOPsQKTâ€‹ = 2 * L * L * d.
    """
    flops_qkT = 2 * context_length * context_length * d_model

    """
    3
    æ³¨æ„åŠ›æƒé‡ä¹˜ Vï¼š ( ğ¿ Ã— ğ¿ ) â‹… ( ğ¿ Ã— ğ‘‘_ğ‘˜ )ï¼ˆæ¯ headï¼‰ï¼Œåˆå¹¶æ‰€æœ‰ headï¼š
    """
    flops_attenV = 2 * context_length * context_length * d_model

    """
    4
    æ³¨æ„åŠ›è¾“å‡ºçš„çº¿æ€§æŠ•å½±ï¼ˆconcat heads å ğ¿ Ã— ğ‘‘ LÃ—d ä¹˜ ğ‘‘ Ã— ğ‘‘ ï¼‰
    """
    flops_proj = 2 * context_length * d_model * d_model

    """
    5
    å‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰çš„ä¸¤ä¸ªçº¿æ€§å±‚ï¼š
    """
    flops_ffn = 4 * context_length * d_model * (4 * d_model)

    """
    6
    æœ€ç»ˆè¯­è¨€æ¨¡å‹å¤´ï¼ˆlogitsï¼‰ï¼š ğ¿ Ã— ğ‘‘ ä¹˜ ğ‘‘ Ã— ğ‘‰ï¼ˆ ğ‘‰ V ä¸ºè¯è¡¨å¤§å°ï¼‰ï¼š
    """
    flops_last = 2 * context_length * d_model * vocab_size

    total_flops = num_layers * (flops_qkv + flops_qkT + flops_attenV + flops_proj + flops_ffn) + flops_last
    print("total flops: " + (str)(total_flops))
    print("X * QKV flops: " + (str)(flops_qkv * num_layers / total_flops))
    print("flops_qkT:" + (str)(flops_qkT * num_layers / total_flops))
    print("flops_attenV: " + (str)(flops_attenV * num_layers / total_flops))
    print("flops_proj" + (str)(flops_proj * num_layers / total_flops))
    print("flops_ffn: " + (str)(flops_ffn * num_layers / total_flops))
    print("flops_final: " + (str)(flops_last / total_flops))
    return total_flops

compute_percentage_eachpart(context_length=1024, num_layers=48, d_model=1600, vocab_size=50257)

"""
answer is:
total flops: 3506703564800
X * QKV flops: 0.2152947079925357
flops_qkT:0.04592953770507428
flops_attenV: 0.04592953770507428
flops_proj0.07176490266417856
flops_ffn: 0.5741192213134285
flops_final: 0.04696209261970862
å¯¹äº GPT-2 XL( L = 1024 ) æœ€å¤š FLOPs æ¥è‡ª FFN(å‰é¦ˆå±‚):
FFN å çº¦ 57.4% çš„æ€» FLOPs, å…¶æ¬¡æ˜¯ Q/K/V çš„ä¸‰ä¸ªæŠ•å½±(çº¦ 21.5%);
æ³¨æ„åŠ›è®¡ç®—æœ¬èº«(QK^T ä¸ attÂ·V)åˆè®¡åªå çº¦ 9.2%ã€‚
åŸç†ä¸Šå› ä¸º FFN çš„çŸ©é˜µä¹˜æ³•è§„æ¨¡æ˜¯ O(L * dçš„å¹³æ–¹ )(éšæ¨¡å‹å®½åº¦d çš„å¹³æ–¹å¢é•¿),
è¿™é‡Œçš„d_model = 1600 >> 1024, ä¸”flops_ffn = 4 * context_length * d_model * (4 * d_model)
å³ffnçš„ç³»æ•°æ˜¯16, æ‰€ä»¥åœ¨æ¨¡å‹é‡Œä¸»å¯¼è®¡ç®—é‡
"""

"""
æ¥ä¸‹æ¥åˆ†åˆ«è®¡ç®—å°,ä¸­,å¤§çš„GPT-2å„ä¸ªéƒ¨åˆ†çš„FLOPS
"""

#å°
print("å°")
compute_percentage_eachpart(context_length=1024, num_layers=12, d_model=768, vocab_size=50257)
print("")

#ä¸­
print("ä¸­")
compute_percentage_eachpart(context_length=1024, num_layers=24, d_model=1024, vocab_size=50257)
print("")

#å¤§
print("å¤§")
compute_percentage_eachpart(context_length=1024, num_layers=36, d_model=1028, vocab_size=50257)
print("")

# GPT-2 XLå¢åŠ context length
print("increase context length: ")
compute_percentage_eachpart(context_length=16384, num_layers=48, d_model=1600, vocab_size=50257)
print("")
"""
increase context length: 
total flops: 133416668364800
X * QKV flops: 0.09054037751093341
flops_qkT:0.30904448857065275
flops_attenV: 0.30904448857065275
flops_proj0.030180125836977805
flops_ffn: 0.24144100669582244
flops_final: 0.019749512814960853
å½“ä¸Šä¸‹æ–‡é•¿åº¦æå¤§(16k)æ—¶, æ³¨æ„åŠ›çš„ O(Lå¹³æ–¹ * d) é¡¹è¿…é€Ÿæˆä¸ºè®¡ç®—ç“¶é¢ˆâ€”â€”æ³¨æ„åŠ›ç›¸å…³çš„çŸ©é˜µä¹˜æ³•å æ¯”ä»åŸå…ˆçš„å°æ¯”ä¾‹è·ƒå‡ï¼Œ
åˆè®¡è¶…è¿‡ 60%ï¼Œè€ŒåŸæœ¬ä¸»å¯¼çš„ FFN(éšdçš„å¹³æ–¹)åè€Œå æ¯”ä¸‹é™
"""