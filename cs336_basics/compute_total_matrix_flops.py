"""
æ³¨: softmaxã€ç¼©æ”¾ã€éçº¿æ€§ã€LayerNorm çš„æ ‡é‡/é€å…ƒç´ è¿ç®—è¢«è§†ä¸ºæ¬¡è¦å¹¶æœªè®¡å…¥çŸ©é˜µä¹˜æ³• FLOPs æ€»å’Œ
"""
def compute_total_matrix_flops(context_length: int, d_model: int, vocab_size: int, num_layers: int):
    """
    1
    Xåˆ†åˆ«ä¹˜ä»¥Q K V
    """
    flops_qkv = 6 * context_length * d_model * d_model

    """
    2
    æŒ‰ head è®¡ç®—çš„ç‚¹ç§¯æ³¨æ„åŠ›å¾—åˆ†ï¼š
      æ¯ head FLOPs = 2 â‹… ğ¿ â‹… ğ¿ â‹… ğ‘‘_ğ‘˜ =2â‹…Lâ‹…Lâ‹…d_k â€‹ ã€‚å› ä¸º âˆ‘ â„ ğ‘‘ ğ‘˜ = ğ‘‘ âˆ‘ h â€‹ d k â€‹ =dï¼Œæ‰€ä»¥åˆå¹¶ä¸º:FLOPsQKTâ€‹ = 2 * L * L * d.
    """
    flops_qkT = 2 * context_length * context_length * d_model

    """
    3
    æ³¨æ„åŠ›æƒé‡ä¹˜ Vï¼š ( ğ¿ Ã— ğ¿ ) â‹… ( ğ¿ Ã— ğ‘‘_ğ‘˜ )ï¼ˆæ¯ headï¼‰ï¼Œåˆå¹¶æ‰€æœ‰ headï¼š
    """
    flops_attenV = 2 * context_length * context_length * d_model

    """
    4
    æ³¨æ„åŠ›è¾“å‡ºçš„çº¿æ€§æŠ•å½±ï¼ˆconcat heads å ğ¿ Ã— ğ‘‘ LÃ—d ä¹˜ ğ‘‘ Ã— ğ‘‘ ï¼‰
    """
    flops_proj = 2 * context_length * d_model * d_model

    """
    5
    å‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰çš„ä¸¤ä¸ªçº¿æ€§å±‚ï¼š
    """
    flops_ffn = 4 * context_length * d_model * (4 * d_model)

    """
    6
    æœ€ç»ˆè¯­è¨€æ¨¡å‹å¤´ï¼ˆlogitsï¼‰ï¼š ğ¿ Ã— ğ‘‘ ä¹˜ ğ‘‘ Ã— ğ‘‰ï¼ˆ ğ‘‰ V ä¸ºè¯è¡¨å¤§å°ï¼‰ï¼š
    """
    flops_last = 2 * context_length * d_model * vocab_size

    total_flops = num_layers * (flops_qkv + flops_qkT + flops_attenV + flops_proj + flops_ffn) + flops_last
    return total_flops

result = compute_total_matrix_flops(context_length=1024, num_layers=48, d_model=1600, vocab_size=50257)
print("æ€»çš„FLOPSæ¬¡æ•°ä¸ºï¼š")
print(result)

"""
answer is :
æ€»çš„FLOPSæ¬¡æ•°ä¸ºï¼š
3506703564800
"""